{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d717566-bc8b-497b-a200-2b365fbf1101",
   "metadata": {},
   "source": [
    "## Reinforcment Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b2f8f-18aa-4f63-9eed-fe809c39269a",
   "metadata": {},
   "source": [
    " In this lesson, you will see how to use reinforcement learning by training your model using penalties. Below is a grid for a self-driving taxi cab that has 4 points to drop off and pick up a passenger.  In the real world, you would also have pedestrians and obstacles, that the Taxi would need to be aware of. Let's venture out and see what our Taxi can do!\n",
    " \n",
    " Below you will import gym and random to create your AI scenario. If you have an error importing gym and random, go to your command prompt/terminal. Go ahead and pip install gym and pip install random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06f8206-eb78-4e52-b0f4-e81af09c3110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : |\u001b[43m \u001b[0m: : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env \n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95245f-4636-4c07-99a4-cbb8654957d6",
   "metadata": {},
   "source": [
    "Now that we have a clear view of our scenario above, let's look at the specific details of our grid:\n",
    "    -The blue \"G\" shows the location of where we will pick up our passengers.\n",
    "    -The pink \"B\" is where a shows where our passenger wants to go.\n",
    "    -The black \"R\" and \"Y\" along with \"G\" and \"B\" are all drop-off locations.\n",
    "    \n",
    "Let's talk about the grid. This grid which we define as \"street's\" is a 5x5 grid that includes the following:\n",
    "    - Where the Taxi is(1 of 25 locations 5x5=25)\n",
    "    - What the current destination is or the possibility(4 locations, R, G, Y, B)\n",
    "    - Where the passenger could be(5 total possibilities, at one of the four locations OR inside the Taxi)\n",
    "    -Then, there are six possibilities for actions(North, South, East, or West. OR pick up and drop off the passenger.\n",
    "    \n",
    "Finally, the reward system! Q-Learning. Q-learning is defined as \"Quality Learning\" It is based on a reward system. Quality represents how useful a given action is in gaining some future reward. OR, if the training model does the wrong action it is penalized. Q-Learning will reward or penalize the taxi at each state.\n",
    "\n",
    "These are the requirements for each state:\n",
    "    -If the drop off is successful taxi receives +20 points\n",
    "    -Every time step is taken while driving a passenger -1 penalty\n",
    "    -If taxi drops off or picks up at the wrong location -10 penalty\n",
    "    -Moving across the wall is not possible.\n",
    "\n",
    "Below, we will set the stage and set the requirements for the taxi location(2,3) the pick-up location 2, and the destination 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84430e6f-2f5c-4d35-8f24-bc0829aa980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = streets.encode(2, 3, 2, 0)\n",
    "\n",
    "streets.s = initial_state\n",
    "\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143f549-f2e8-42b5-821f-51acf9c55b04",
   "metadata": {},
   "source": [
    "Let's take a look at the reward table for this initial state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b1c45a-b84a-4215-a872-d68503f3589e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 368, -1, False)],\n",
       " 1: [(1.0, 168, -1, False)],\n",
       " 2: [(1.0, 288, -1, False)],\n",
       " 3: [(1.0, 248, -1, False)],\n",
       " 4: [(1.0, 268, -10, False)],\n",
       " 5: [(1.0, 268, -10, False)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets.P[initial_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82f1dd-cd59-4001-938d-f541c1757e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
